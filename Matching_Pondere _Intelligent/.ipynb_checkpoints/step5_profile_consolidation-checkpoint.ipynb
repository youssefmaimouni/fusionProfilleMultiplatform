{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1d0ae9-4a3b-4929-aa2d-1417bd5c1ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Consolidation de 605 identit√©s unifi√©es...\n",
      "\n",
      "‚úÖ Fusion termin√©e !\n",
      "üìÅ Fichier sauvegard√© : output/final_unified_profiles.json\n",
      "üìä 605 profils unifi√©s\n",
      "üìß 427/605 avec email\n",
      "üíº 0/605 avec poste\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "√âTAPE 4 ‚Äì FUSION DES PROFILS (Profil Unique Consolid√©)\n",
    "Objectif : cr√©er un profil global √† partir des identit√©s unifi√©es (triplets + paires r√©siduelles)\n",
    "\n",
    "Conform√©ment au cahier des charges :\n",
    "- Priorit√© par plateforme pour chaque attribut\n",
    "- Agr√©gation coh√©rente (texte / num√©rique)\n",
    "- Gestion des conflits\n",
    "- G√©n√©ration de profil structur√©\n",
    "- Sauvegarde en JSON\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# üîù Priorit√© des plateformes selon le type d'information\n",
    "PLATFORM_PRIORITY = {\n",
    "    \"fullName\":        [\"linkedin\", \"github\", \"twitter\"],\n",
    "    \"jobTitle\":        [\"linkedin\"],\n",
    "    \"company\":         [\"linkedin\"],\n",
    "    \"bio\":             [\"linkedin\", \"twitter\", \"github\"],\n",
    "    \"location\":        [\"linkedin\", \"twitter\", \"github\"],\n",
    "    \"email\":           [\"github\", \"linkedin\", \"twitter\"],\n",
    "    \"publicRepos\":     [\"github\"],\n",
    "    \"followersCount\":  [\"twitter\", \"linkedin\", \"github\"],  # on prendra le max plus tard\n",
    "}\n",
    "\n",
    "# üìä Champs num√©riques : on appliquera max() ou moyenne si besoin\n",
    "NUMERIC_FIELDS = {\"followersCount\", \"publicRepos\", \"followingCount\"}\n",
    "\n",
    "def get_best_text_value(profiles, field):\n",
    "    \"\"\"R√©cup√®re la meilleure valeur textuelle selon la priorit√© des plateformes.\"\"\"\n",
    "    if field not in PLATFORM_PRIORITY:\n",
    "        # Fallback : prendre la premi√®re non vide\n",
    "        for p in profiles:\n",
    "            if p.get(field):\n",
    "                return p[field]\n",
    "        return None\n",
    "\n",
    "    for platform in PLATFORM_PRIORITY[field]:\n",
    "        for p in profiles:\n",
    "            if p[\"platform\"].lower() == platform and p.get(field):\n",
    "                return p[field]\n",
    "    # Si aucune priorit√© ne matche, chercher dans n'importe quelle plateforme\n",
    "    for p in profiles:\n",
    "        if p.get(field):\n",
    "            return p[field]\n",
    "    return None\n",
    "\n",
    "def aggregate_text_fields(profiles, field):\n",
    "    \"\"\"Concat√®ne les valeurs uniques et non vides d‚Äôun champ textuel.\"\"\"\n",
    "    values = set()\n",
    "    for p in profiles:\n",
    "        val = p.get(field)\n",
    "        if val and isinstance(val, str):\n",
    "            val = val.strip()\n",
    "            if val:\n",
    "                values.add(val)\n",
    "    return \" | \".join(sorted(values)) if values else None\n",
    "\n",
    "def aggregate_numeric_fields(profiles, field):\n",
    "    \"\"\"Retourne la valeur maximale pour les champs num√©riques.\"\"\"\n",
    "    values = []\n",
    "    for p in profiles:\n",
    "        val = p.get(field)\n",
    "        if isinstance(val, (int, float)) and val is not None:\n",
    "            values.append(val)\n",
    "    return max(values) if values else None\n",
    "\n",
    "def consolidate_one_identity(cluster):\n",
    "    \"\"\"Construit un profil consolid√© √† partir d‚Äôun cluster (paire ou triplet).\"\"\"\n",
    "    profiles = cluster[\"profiles\"]\n",
    "    unified_id = cluster[\"unified_id\"]\n",
    "\n",
    "    # Champs avec priorit√© explicite\n",
    "    consolidated = {\n",
    "        \"unified_id\": unified_id,\n",
    "        \"fullName\": get_best_text_value(profiles, \"fullName\"),\n",
    "        \"jobTitle\": get_best_text_value(profiles, \"jobTitle\"),\n",
    "        \"company\": get_best_text_value(profiles, \"company\"),\n",
    "        \"email\": get_best_text_value(profiles, \"email\"),\n",
    "        \"location\": get_best_text_value(profiles, \"location\"),\n",
    "    }\n",
    "\n",
    "    # Champs agr√©g√©s (texte)\n",
    "    consolidated[\"bio\"] = aggregate_text_fields(profiles, \"bio\")\n",
    "\n",
    "    # Champs num√©riques (max)\n",
    "    for field in NUMERIC_FIELDS:\n",
    "        consolidated[field] = aggregate_numeric_fields(profiles, field)\n",
    "\n",
    "    # Sources\n",
    "    consolidated[\"platforms_sources\"] = sorted({p[\"platform\"] for p in profiles})\n",
    "\n",
    "    # Nettoyage final : supprimer les cl√©s avec valeur None\n",
    "    return {k: v for k, v in consolidated.items() if v is not None}\n",
    "\n",
    "def main():\n",
    "    output_dir = Path(\"output\")\n",
    "    input_path = output_dir / \"unified_hybrid.json\"\n",
    "    output_path = output_dir / \"final_unified_profiles.json\"\n",
    "\n",
    "    if not input_path.exists():\n",
    "        print(f\"‚ùå Fichier d'entr√©e introuvable : {input_path}\")\n",
    "        return\n",
    "\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        hybrid_clusters = json.load(f)\n",
    "\n",
    "    print(f\"üîÑ Consolidation de {len(hybrid_clusters)} identit√©s unifi√©es...\")\n",
    "\n",
    "    consolidated_profiles = []\n",
    "    for cluster in hybrid_clusters:\n",
    "        profile = consolidate_one_identity(cluster)\n",
    "        consolidated_profiles.append(profile)\n",
    "\n",
    "    # Sauvegarde\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(consolidated_profiles, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # Stats\n",
    "    total = len(consolidated_profiles)\n",
    "    with_email = sum(1 for p in consolidated_profiles if \"email\" in p)\n",
    "    with_job = sum(1 for p in consolidated_profiles if \"jobTitle\" in p)\n",
    "\n",
    "    print(f\"\\n‚úÖ Fusion termin√©e !\")\n",
    "    print(f\"üìÅ Fichier sauvegard√© : {output_path}\")\n",
    "    print(f\"üìä {total} profils unifi√©s\")\n",
    "    print(f\"üìß {with_email}/{total} avec email\")\n",
    "    print(f\"üíº {with_job}/{total} avec poste\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf9f931-3cc0-47b9-9d72-6ea9be35d2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
