{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63bd15ea-d53f-4af7-8cd4-cf7da4020741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier unifi√© sauvegard√© : global_tech_talents_morocco.csv\n",
      "üìä 9101 profils uniques, dont 2584 bas√©s au Maroc.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def clean_location(loc):\n",
    "    \"\"\"Normalise les localisations pour d√©tecter le Maroc\"\"\"\n",
    "    if pd.isna(loc):\n",
    "        return \"\", False\n",
    "    loc = str(loc).strip()\n",
    "    loc_lower = loc.lower()\n",
    "    if \"morocco\" in loc_lower or \"maroc\" in loc_lower:\n",
    "        # Utiliser maxsplit comme mot-cl√© pour √©viter le DeprecationWarning\n",
    "        city_match = re.split(r'[,;]', loc, maxsplit=1)[0].strip()\n",
    "        return f\"{city_match}, Morocco\", True\n",
    "    return loc, False\n",
    "\n",
    "def extract_skills_from_text(text):\n",
    "    \"\"\"Extraction simple de comp√©tences cl√©s\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    all_skills = []\n",
    "    skill_keywords = [\n",
    "        \"nlp\", \"natural language\", \"bert\", \"llm\", \"transformer\",\n",
    "        \"rust\", \"python\", \"java\", \"swift\", \"javascript\", \"typescript\",\n",
    "        \"docker\", \"kubernetes\", \"jenkins\", \"terraform\", \"ci/cd\",\n",
    "        \"coreml\", \"pytorch\", \"tensorflow\", \"machine learning\",\n",
    "        \"computer vision\", \"opencv\", \"object detection\",\n",
    "        \"arabic\", \"french\", \"multilingual\",\n",
    "        \"graph\", \"knowledge graph\", \"semantic search\", \"vector search\",\n",
    "        \"ios\", \"android\", \"flutter\", \"react\", \"angular\", \"spring\",\n",
    "        \"mysql\", \"mongodb\", \"postgresql\"\n",
    "    ]\n",
    "    for kw in skill_keywords:\n",
    "        if kw in text:\n",
    "            all_skills.append(kw.title())\n",
    "    return \"; \".join(sorted(set(all_skills)))\n",
    "\n",
    "def normalize_github(df):\n",
    "    df = df.copy()\n",
    "    df[\"full_name\"] = df.get(\"name\", \"\")\n",
    "    df[\"username\"] = df.get(\"username\", \"\")\n",
    "    df[\"bio\"] = df.get(\"bio\", \"\")\n",
    "    df[\"current_role\"] = df[\"bio\"].str.split(\"|\").str[0] if \"bio\" in df.columns else \"\"\n",
    "    df[\"company\"] = df.get(\"company\", \"\")\n",
    "    df[\"email\"] = df.get(\"email\", \"\")\n",
    "    df[\"location\"], df[\"is_based_in_morocco\"] = zip(*df.get(\"location\", pd.Series([None]*len(df))).apply(clean_location))\n",
    "    df[\"github_url\"] = df.get(\"profile_url\", \"\").str.strip()\n",
    "    df[\"avatar_url\"] = df.get(\"avatar_url\", \"\")\n",
    "    df[\"projects_summary\"] = df.get(\"repo_descriptions\", \"\").astype(str)\n",
    "    df[\"skills\"] = df[\"projects_summary\"].apply(extract_skills_from_text)\n",
    "    df[\"linkedin_url\"] = \"\"\n",
    "    df[\"twitter_url\"] = \"\"\n",
    "    df[\"primary_platform\"] = \"github\"\n",
    "    df[\"source_files\"] = \"github.csv\"\n",
    "    return df\n",
    "\n",
    "def normalize_linkedin(df):\n",
    "    df = df.copy()\n",
    "    df[\"full_name\"] = df.get(\"full_name\", \"\")\n",
    "    df[\"username\"] = df.get(\"username\", \"\")\n",
    "    df[\"bio\"] = df.get(\"about\", \"\")\n",
    "    df[\"current_role\"] = df.get(\"headline\", \"\")\n",
    "    df[\"company\"] = \"\"\n",
    "    df[\"email\"] = \"\"\n",
    "    df[\"location\"], df[\"is_based_in_morocco\"] = zip(*df.get(\"location\", pd.Series([None]*len(df))).apply(clean_location))\n",
    "    df[\"avatar_url\"] = df.get(\"profile_photo\", \"\")\n",
    "    df[\"github_url\"] = \"\"\n",
    "    df[\"linkedin_url\"] = \"https://www.linkedin.com/in/\" + df[\"username\"].astype(str)\n",
    "    df[\"twitter_url\"] = \"\"\n",
    "    df[\"projects_summary\"] = df.get(\"projects\", \"\").astype(str)\n",
    "    df[\"skills\"] = (df[\"bio\"].fillna(\"\") + \" \" + df[\"projects_summary\"]).apply(extract_skills_from_text)\n",
    "    df[\"primary_platform\"] = \"linkedin\"\n",
    "    df[\"source_files\"] = \"linkedin.csv\"\n",
    "    return df\n",
    "\n",
    "def normalize_twitter(df):\n",
    "    df = df.copy()\n",
    "    # Utiliser 'Twitter Username' comme username si colonne diff√©rente\n",
    "    if \"Twitter Username\" in df.columns:\n",
    "        df[\"username\"] = df[\"Twitter Username\"]\n",
    "    else:\n",
    "        df[\"username\"] = df.get(\"username\", \"\")\n",
    "    df[\"full_name\"] = df.get(\"full_name\", df.get(\"bio\", \"\"))  # fallback\n",
    "    df[\"bio\"] = df.get(\"bio\", \"\")\n",
    "    df[\"current_role\"] = df[\"bio\"]  # souvent dans la bio\n",
    "    df[\"company\"] = \"\"\n",
    "    df[\"email\"] = \"\"\n",
    "    df[\"location\"] = \"\"\n",
    "    df[\"is_based_in_morocco\"] = False\n",
    "    df[\"avatar_url\"] = df.get(\"image_url\", \"\")\n",
    "    df[\"github_url\"] = \"\"\n",
    "    df[\"linkedin_url\"] = \"\"\n",
    "    df[\"twitter_url\"] = \"https://twitter.com/\" + df[\"username\"].astype(str)\n",
    "    df[\"projects_summary\"] = \"\"\n",
    "    df[\"skills\"] = df[\"bio\"].apply(extract_skills_from_text)\n",
    "    df[\"primary_platform\"] = \"twitter\"\n",
    "    df[\"source_files\"] = \"twitter.csv\"\n",
    "    return df\n",
    "\n",
    "# Colonnes du sch√©ma unifi√©\n",
    "UNIFIED_COLS = [\n",
    "    \"full_name\", \"username\", \"primary_platform\", \"email\", \"location\",\n",
    "    \"is_based_in_morocco\", \"bio\", \"current_role\", \"company\",\n",
    "    \"linkedin_url\", \"github_url\", \"twitter_url\", \"avatar_url\",\n",
    "    \"skills\", \"projects_summary\", \"source_files\"\n",
    "]\n",
    "\n",
    "def main():\n",
    "    # Charger les fichiers (√† adapter selon ton chemin)\n",
    "    github_df = pd.read_csv(\"github.csv\", on_bad_lines='skip')\n",
    "    linkedin_df = pd.read_csv(\"linkedin.csv\", on_bad_lines='skip')\n",
    "    twitter_df = pd.read_csv(\"twitter.csv\", on_bad_lines='skip')\n",
    "\n",
    "    # Normaliser chaque source\n",
    "    gh_norm = normalize_github(github_df)[UNIFIED_COLS]\n",
    "    li_norm = normalize_linkedin(linkedin_df)[UNIFIED_COLS]\n",
    "    tw_norm = normalize_twitter(twitter_df)[UNIFIED_COLS]\n",
    "\n",
    "    # Combiner\n",
    "    unified = pd.concat([gh_norm, li_norm, tw_norm], ignore_index=True)\n",
    "\n",
    "    # --- D√©doublonnage simple (optionnel mais recommand√©) ---\n",
    "    # Regrouper par full_name + is_based_in_morocco (√† am√©liorer si besoin)\n",
    "    # On garde la ligne avec le plus d'infos (ex: celle avec email ou plus de skills)\n",
    "    unified[\"info_score\"] = (\n",
    "        unified[\"email\"].notna().astype(int) * 2 +\n",
    "        unified[\"skills\"].str.len() / 100 +\n",
    "        unified[\"projects_summary\"].str.len() / 1000\n",
    "    )\n",
    "    unified = unified.sort_values(\"info_score\", ascending=False)\n",
    "    unified = unified.drop_duplicates(subset=[\"full_name\"], keep=\"first\")\n",
    "    unified = unified.drop(columns=[\"info_score\"])\n",
    "\n",
    "    # Sauvegarder\n",
    "    output_file = \"global_tech_talents_morocco.csv\"\n",
    "    unified.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"‚úÖ Fichier unifi√© sauvegard√© : {output_file}\")\n",
    "    print(f\"üìä {len(unified)} profils uniques, dont {unified['is_based_in_morocco'].sum()} bas√©s au Maroc.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ddde4-a9d1-4c58-b9a1-8da6a4735f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
